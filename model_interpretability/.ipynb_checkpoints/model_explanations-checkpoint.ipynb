{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability with LIME and SHAP\n",
    "\n",
    "This notebook demonstrates how to explain AI model predictions using LIME and SHAP, and compares them with inherently interpretable models like decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Dataset\n",
    "\n",
    "We'll create a synthetic dataset representing a loan approval system with various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features\n",
    "income = np.random.normal(60000, 20000, n_samples)\n",
    "age = np.random.normal(40, 10, n_samples)\n",
    "years_employed = np.random.normal(10, 5, n_samples)\n",
    "debt_ratio = np.random.normal(0.3, 0.1, n_samples)\n",
    "credit_score = np.random.normal(700, 50, n_samples)\n",
    "\n",
    "# Create feature matrix\n",
    "X = np.column_stack([income, age, years_employed, debt_ratio, credit_score])\n",
    "\n",
    "# Generate target (loan approval) based on a complex rule\n",
    "y = (credit_score > 720) & \\\n",
    "    ((income > 50000) | (years_employed > 5)) & \\\n",
    "    (debt_ratio < 0.4)\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = ['Income', 'Age', 'Years_Employed', 'Debt_Ratio', 'Credit_Score']\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    "We'll train both a Random Forest (black-box model) and a Decision Tree (interpretable model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_model.score(X_test_scaled, y_test):.3f}\")\n",
    "print(f\"Decision Tree Accuracy: {dt_model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME Explanation\n",
    "\n",
    "Let's use LIME to explain predictions for a specific test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_scaled,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['Denied', 'Approved'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Select a test case\n",
    "test_idx = 0\n",
    "test_instance = X_test_scaled[test_idx]\n",
    "\n",
    "# Generate LIME explanation\n",
    "exp = explainer.explain_instance(\n",
    "    test_instance, \n",
    "    rf_model.predict_proba,\n",
    "    num_features=len(feature_names)\n",
    ")\n",
    "\n",
    "# Plot LIME explanation\n",
    "plt.figure(figsize=(10, 6))\n",
    "exp.as_pyplot_figure()\n",
    "plt.title('LIME Explanation for Test Instance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis\n",
    "\n",
    "Now let's use SHAP to understand feature importance and individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "\n",
    "# Calculate SHAP values for test set\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Plot summary plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values[1], X_test_scaled, feature_names=feature_names)\n",
    "plt.title('SHAP Summary Plot')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot force plot for the same test instance\n",
    "plt.figure(figsize=(12, 4))\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[1][test_idx],\n",
    "    X_test_scaled[test_idx],\n",
    "    feature_names=feature_names,\n",
    "    matplotlib=True\n",
    ")\n",
    "plt.title('SHAP Force Plot for Test Instance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Decision Tree Visualization\n",
    "\n",
    "Finally, let's visualize the decision tree for comparison with the black-box model explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=feature_names,\n",
    "          class_names=['Denied', 'Approved'],\n",
    "          filled=True,\n",
    "          rounded=True)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates three different approaches to model interpretability:\n",
    "\n",
    "1. **LIME**: Provides local explanations by approximating the model's behavior around specific instances\n",
    "2. **SHAP**: Offers both global and local interpretability through Shapley values\n",
    "3. **Decision Trees**: Provides inherent interpretability through a hierarchical structure\n",
    "\n",
    "Each method has its strengths:\n",
    "- LIME is great for understanding individual predictions\n",
    "- SHAP provides consistent and theoretically sound feature importance\n",
    "- Decision trees offer direct interpretability but might sacrifice some performance\n",
    "\n",
    "The choice of method depends on your specific needs for model interpretation and the trade-off between model performance and interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
